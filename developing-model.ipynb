{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Punctation Restoration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Any, Union, List, Optional, Literal, Dict, Iterator, Iterable, Tuple\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import json, sys, os\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from transformers import AutoModel, AutoTokenizer, PreTrainedTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import DictConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "logger = logging.getLogger('lightning')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "ZeroClass = Literal['O']\n",
    "PunctuationMark = Literal['.', ',', '?', '!', '-', '...']\n",
    "Label = Union[ZeroClass, PunctuationMark]\n",
    "\n",
    "ValidationEpochOutputs = Union[\n",
    "    List[\n",
    "        Union[torch.Tensor, Dict[str, Any]]\n",
    "    ],\n",
    "\n",
    "    List[List[\n",
    "        Union[torch.Tensor, Dict[str, Any]]\n",
    "    ]]\n",
    "]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DatasetItem:\n",
    "    first_token_pos: List[int]\n",
    "    token_ids: List[int]\n",
    "    label_ids: List[int]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert len(self.token_ids) == len(self.label_ids), \\\n",
    "            'the number of tokens does not match the number of labels'\n",
    "        assert len(self.first_token_pos) < len(self.token_ids), \\\n",
    "            'there cannot be more words, than subtokens'\n",
    "        assert all(pos < len(self.token_ids) for pos in self.first_token_pos), \\\n",
    "            'word\\'s first token position cannot exceed the number of subtokens'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class PunctuationRestorationDataModule(pl.LightningDataModule):\n",
    "    PUNCTUATION_MARKS = ['.', ',', '?', '!', '-', '...']\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: DictConfig\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.tokenizer_name: str = cfg.model.encoder.tokenizer\n",
    "        self.tokenizer: Optional[PreTrainedTokenizer] = None\n",
    "\n",
    "        self.train_batch_size: int = cfg.trainer.train_batch_size\n",
    "        self.val_batch_size: int = cfg.trainer.val_batch_size\n",
    "        self.test_batch_size: int = cfg.trainer.test_batch_size\n",
    "        self.predict_batch_size: int = cfg.trainer.predict_batch_size\n",
    "\n",
    "        self.train_dataset: Optional[Iterable[DatasetItem]] = None\n",
    "        self.val_dataset: Optional[Iterable[DatasetItem]] = None\n",
    "        self.test_dataset: Optional[Iterable[DatasetItem]] = None\n",
    "        self.predict_dataset: Optional[Iterable[DatasetItem]] = None\n",
    "\n",
    "        self.idx2label: List[Label] = ['O'] + self.PUNCTUATION_MARKS\n",
    "        self.label2idx: Dict[Label, int] = {label: idx for idx, label in enumerate(self.idx2label)}\n",
    "        self.num_classes: int = len(self.idx2label)\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n",
    "        del tokenizer\n",
    "\n",
    "    def _parse_tsv_input(self, filepath: Path) -> Iterable[DatasetItem]:\n",
    "        pass\n",
    "\n",
    "    # TODO max_seq_len\n",
    "    def _parse_json_input(self, filepath: Path) -> Iterable[DatasetItem]:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        items: List[DatasetItem] = []\n",
    "        for document in data[:100]:\n",
    "            first_token_pos: List[int] = []\n",
    "            token_ids: List[int] = []\n",
    "            label_ids: List[int] = []\n",
    "            for word in document['words']:\n",
    "                if len(token_ids) >= self.cfg.trainer.max_seq_len-2:\n",
    "                    break\n",
    "\n",
    "                first_token_pos.append(len(token_ids))\n",
    "\n",
    "                subtokens = self.tokenizer.tokenize(word['word'], )\n",
    "                token_ids.extend(self.tokenizer.convert_tokens_to_ids(subtokens))\n",
    "\n",
    "                label_ids.extend([self.label2idx.get(word['punctuation'], 0)] + [0] * (len(subtokens) - 1))\n",
    "\n",
    "            token_ids = [self.tokenizer.cls_token_id] + token_ids[:self.cfg.trainer.max_seq_len-2] + [self.tokenizer.sep_token_id]\n",
    "            label_ids = [0] + label_ids[:self.cfg.trainer.max_seq_len-2] + [0]\n",
    "\n",
    "            items.append(DatasetItem(first_token_pos, token_ids, label_ids))\n",
    "\n",
    "        return items\n",
    "\n",
    "    # TODO other formats?\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n",
    "\n",
    "        if stage is None or stage == 'train':\n",
    "            if self.cfg.data.train.endswith('.json'):\n",
    "                self.train_dataset = self._parse_json_input(self.cfg.data.train)\n",
    "            else:\n",
    "                raise NotImplementedError('unknown format')\n",
    "\n",
    "        if stage is None or stage == 'val':\n",
    "            if self.cfg.data.val.endswith('.json'):\n",
    "                self.val_dataset = self._parse_json_input(self.cfg.data.val)\n",
    "            else:\n",
    "                raise NotImplementedError('unknown format')\n",
    "\n",
    "        if stage is None or stage == 'test':\n",
    "            if self.cfg.data.test.endswith('.json'):\n",
    "                self.test_dataset = self._parse_json_input(self.cfg.data.test)\n",
    "            else:\n",
    "                raise NotImplementedError('unknown format')\n",
    "\n",
    "        if stage is None or stage == 'predict':\n",
    "            if self.cfg.data.predict.endswith('.json'):\n",
    "                self.predict_dataset = self._parse_json_input(self.cfg.data.predict)\n",
    "            else:\n",
    "                raise NotImplementedError('unknown format')\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.train_batch_size,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=self.collator,\n",
    "                          num_workers=6)\n",
    "\n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.val_batch_size,\n",
    "                          shuffle=False,\n",
    "                          collate_fn=self.collator,\n",
    "                          num_workers=3)\n",
    "\n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self.test_dataset,\n",
    "                          batch_size=self.test_batch_size,\n",
    "                          shuffle=False,\n",
    "                          collate_fn=self.collator,\n",
    "                          num_workers=3)\n",
    "\n",
    "    def predict_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self.predict_dataset,\n",
    "                          batch_size=self.predict_batch_size,\n",
    "                          shuffle=False,\n",
    "                          collate_fn=self.collator,\n",
    "                          num_workers=3)\n",
    "\n",
    "    def collator(self, batch: Iterable[DatasetItem]) -> Tuple[List[List[int]], List[torch.Tensor], List[torch.Tensor]]:\n",
    "        first_token_pos = [item.first_token_pos for item in batch]\n",
    "        token_ids = [item.token_ids for item in batch]\n",
    "        label_ids = [torch.tensor(item.label_ids) for item in batch]\n",
    "\n",
    "        padded_token_ids = [self.tokenizer.pad(\n",
    "            {'input_ids': tokens},\n",
    "            padding='longest',\n",
    "            return_tensors='pt'\n",
    "        ) for tokens in token_ids]\n",
    "\n",
    "        return first_token_pos, padded_token_ids, label_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "configs        datatypes.py\t       main.py\t __pycache__\r\n",
      "data\t       developing-model.ipynb  model.py  requirements.txt\r\n",
      "datamodule.py  lightning_logs\t       outputs\t scripts\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 8, 9, 10, 12, 14, 15, 16, 19, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125]\n",
      "\n",
      "{'input_ids': tensor([    0,  2181, 10347,  7990,  1055,  2289,    76,  6425,  4323,  4714,\n",
      "         2282,  4737,  2178,  7418,  5657,  6105, 13087, 25528,  3453,  1024,\n",
      "         2003,    93, 17861,  4506,  2003,    93,  2572, 16425,  2040,  5060,\n",
      "        42135,  2642, 26168,  2408, 49699,  9791,  9843,  1019,  2194,  2254,\n",
      "        11938,  2181, 10347,  7990,  1055,  2289,    76,  6425,  4323, 13944,\n",
      "        37028, 35023, 13376, 43704,  5874, 12593, 34122,  1029,  1019,  2289,\n",
      "           76,  6425,  1997, 14324,  2040, 27743, 19801,  1998, 12093, 25528,\n",
      "         3453,  1024,  5114,  2022,  2408, 49699,  9791,  9843, 10387,  8905,\n",
      "        13789, 12593,  1046,  3131,  2431,  2291,  1998,  2553,  2291,  3420,\n",
      "        20488,  1998,  6530,  3723, 25062, 29592,  2944, 12462,  1009,  3938,\n",
      "        11938, 14324,  2040, 13171, 31267,  1998,  2194, 12093,  9460,  2022,\n",
      "         1019,  5235,  6105, 13087, 15922,  2040,  6012, 15895, 12593, 32710,\n",
      "         2413,  1998,  9302, 11351,  8112,  2634,  3695,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 2, 0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path='configs/'):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "    datamodule = PunctuationRestorationDataModule(cfg)\n",
    "    datamodule.setup()\n",
    "\n",
    "    dataloader = datamodule.test_dataloader()\n",
    "\n",
    "    for item in dataloader:\n",
    "        first_token_pos, token_ids, label_ids = item\n",
    "\n",
    "        print(first_token_pos[0], end='\\n\\n')\n",
    "        print(token_ids[0], end='\\n\\n')\n",
    "        print(label_ids[0], end='\\n\\n')\n",
    "\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17556/551439658.py:46: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def _calculate_metrics(self, preds: npt.NDArray[np.int], golds: npt.NDArray[np.int]) -> Dict[str, Any]:\n"
     ]
    }
   ],
   "source": [
    "class RestorationModel(pl.LightningModule):\n",
    "    def __init__(self, cfg: DictConfig, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.save_hyperparameters(cfg)\n",
    "\n",
    "        self.loss_weights = torch.tensor([self.hparams.trainer.zero_class_weight] + [1.0 for _ in range(self.num_classes - 1)])\n",
    "\n",
    "        self.encoder = AutoModel.from_pretrained(cfg.model.encoder.name)\n",
    "        self.head = self._construct_head()\n",
    "\n",
    "        self.head.apply(self._init_weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform(module.weight)\n",
    "            module.bias.data.fill_(0.01)\n",
    "\n",
    "    def _construct_head(self) -> nn.Module:\n",
    "        if self.hparams.model.head.architecture == 'mlp':\n",
    "            mlp_config = self.hparams.model.head.mlp\n",
    "\n",
    "            head = nn.Sequential()\n",
    "            prev_layer_dim = self.encoder.config.hidden_size\n",
    "            for i in range(mlp_config.num_layers - 1):\n",
    "                layer = nn.Linear(prev_layer_dim, mlp_config.num_hiddens)\n",
    "                prev_layer_dim = layer.out_features\n",
    "\n",
    "                if mlp_config.nonlinearity == 'relu':\n",
    "                    nonlinearity = nn.ReLU()\n",
    "                else:\n",
    "                    raise ValueError('unknown nonlinearity')\n",
    "\n",
    "                head.add_module(f'cls{i}', layer)\n",
    "                head.add_module(f'cls{i}_nonlinearity', nonlinearity)\n",
    "\n",
    "            head.add_module('cls_pred', nn.Linear(prev_layer_dim, self.num_classes))\n",
    "\n",
    "            return head\n",
    "\n",
    "        else:\n",
    "            raise ValueError('unknown head architecture')\n",
    "\n",
    "    def _calculate_metrics(self, preds: npt.NDArray[np.int], golds: npt.NDArray[np.int]) -> Dict[str, Any]:\n",
    "        labels = list(range(1, self.trainer.datamodule.num_classes))\n",
    "        pr_micro, rc_micro, f1_micro, _ = \\\n",
    "            precision_recall_fscore_support(golds, preds, average='micro', zero_division=0, labels=labels)\n",
    "        pr_macro, rc_macro, f1_macro, _ = \\\n",
    "            precision_recall_fscore_support(golds, preds, average='macro', zero_division=0, labels=labels)\n",
    "        pr_weighted, rc_weighted, f1_weighted, _ = \\\n",
    "            precision_recall_fscore_support(golds, preds, average='weighted', zero_division=0, labels=labels)\n",
    "        pr_per_label, rc_per_label, f1_per_label, _ = \\\n",
    "            precision_recall_fscore_support(golds, preds, average=None, zero_division=0, labels=labels)\n",
    "\n",
    "        metrics = {\n",
    "                f'pr_{self.trainer.datamodule.idx2label[key]}': val\n",
    "                for key, val in zip(range(1, self.trainer.datamodule.num_classes), pr_per_label)\n",
    "            } | {\n",
    "                f'rc_{self.trainer.datamodule.idx2label[key]}': val\n",
    "                for key, val in zip(range(1, self.trainer.datamodule.num_classes), rc_per_label)\n",
    "            } | {\n",
    "                f'f1_{self.trainer.datamodule.idx2label[key]}': val\n",
    "                for key, val in zip(range(1, self.trainer.datamodule.num_classes), f1_per_label)\n",
    "        }\n",
    "\n",
    "        metrics.update({\n",
    "            'pr_micro': pr_micro,\n",
    "            'rc_micro': rc_micro,\n",
    "            'f1_micro': f1_micro,\n",
    "            'pr_macro': pr_macro,\n",
    "            'rc_macro': rc_macro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'pr_weighted': pr_weighted,\n",
    "            'rc_weighted': rc_weighted,\n",
    "            'f1_weighted': f1_weighted,\n",
    "        })\n",
    "        return metrics\n",
    "\n",
    "    def common_step(self, batch) -> (List[torch.Tensor], List[torch.Tensor], float):\n",
    "        first_token_pos, model_inputs_batch, label_ids_batch = batch\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_golds = []\n",
    "        loss = 0\n",
    "\n",
    "        for model_inputs, label_ids in zip(model_inputs_batch, label_ids_batch):\n",
    "            encoded = self.encoder(\n",
    "                input_ids=model_inputs['input_ids'].unsqueeze(0),\n",
    "                attention_mask=model_inputs['attention_mask'].unsqueeze(0),\n",
    "                return_dict=True\n",
    "            )['last_hidden_state'].squeeze()\n",
    "\n",
    "            logits = self.head(encoded)\n",
    "\n",
    "            batch_preds.append(logits)\n",
    "            batch_golds.append(label_ids)\n",
    "\n",
    "            loss += F.cross_entropy(logits, label_ids, weight=self.loss_weights)\n",
    "\n",
    "        return batch_preds, batch_golds, loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        preds, golds, loss = self.common_step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\n",
    "            'loss': loss\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        preds, golds, loss = self.common_step(batch)\n",
    "        self.log('val_loss', loss)\n",
    "        return {\n",
    "            'preds': preds,\n",
    "            'golds': golds\n",
    "        }\n",
    "\n",
    "    # FIXME shouldn't it be validation_step_end instead? https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#validating-with-dataparallel\n",
    "    def validation_epoch_end(self, validation_step_outputs: ValidationEpochOutputs) -> None:\n",
    "        # TODO as a future feature we can aggregate results for each dataloader separately\n",
    "        # flattening outputs from dataloaders if there are multiple\n",
    "        if validation_step_outputs and isinstance(validation_step_outputs[0], list):\n",
    "            outputs = [\n",
    "                step_output\n",
    "                for dataloader_output in validation_step_outputs\n",
    "                for step_output in dataloader_output\n",
    "            ]\n",
    "        else:\n",
    "            outputs = validation_step_outputs\n",
    "\n",
    "        preds_logits = torch.cat([pred for step_output in outputs for pred in step_output['preds']])\n",
    "        preds: torch.Tensor = torch.max(preds_logits, dim=1).indices\n",
    "        golds: torch.Tensor = torch.cat([gold for step_output in outputs for gold in step_output['golds']])\n",
    "\n",
    "        preds_numpy = preds.cpu().numpy()\n",
    "        golds_numpy = golds.cpu().numpy()\n",
    "\n",
    "        # rank_zero_info(str(preds_numpy))\n",
    "        # rank_zero_info(str(golds_numpy))\n",
    "        rank_zero_info(f'tp: {np.sum(np.where(golds_numpy != 0, preds_numpy == golds_numpy, False))}')\n",
    "        rank_zero_info(f'nonzero count:, {np.count_nonzero(preds_numpy)}')\n",
    "        rank_zero_info(f'preds_logits: {preds_logits[0]}')\n",
    "\n",
    "        metrics = self._calculate_metrics(preds_numpy, golds_numpy)\n",
    "        self.log_dict(metrics, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        preds, golds, loss = self.common_step(batch)\n",
    "        self.log('test_loss', loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.trainer.learning_rate)\n",
    "        return optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities import rank_zero_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class MetricsLoggingCallback(pl.Callback):\n",
    "    def on_validation_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        micro_recall = trainer.callback_metrics['rc_micro']\n",
    "        micro_precision = trainer.callback_metrics['pr_micro']\n",
    "        micro_f1 = trainer.callback_metrics['f1_micro']\n",
    "\n",
    "        weighted_recall = trainer.callback_metrics['rc_micro']\n",
    "        weighted_precision = trainer.callback_metrics['pr_micro']\n",
    "        weighted_f1 = trainer.callback_metrics['f1_weighted']\n",
    "\n",
    "        rank_zero_info(f'micro // f1: {100*micro_f1:.2f}, recall: {100*micro_recall:.2f}, precision: {100*micro_precision:.2f}')\n",
    "        rank_zero_info(f'weighted // f1: {100*weighted_f1:.2f}, recall: {100*weighted_recall:.2f}, precision: {100*weighted_precision:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path='configs/'):\n",
    "    cfg = compose(config_name='config.yaml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "datamodule = PunctuationRestorationDataModule(cfg)\n",
    "datamodule.setup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.sso.sso_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.sso.sso_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_17556/551439658.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(module.weight)\n"
     ]
    }
   ],
   "source": [
    "model = RestorationModel(cfg, num_classes=7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1764: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | BertModel  | 124 M \n",
      "1 | head    | Sequential | 99.3 K\n",
      "---------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "498.169   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tp: 21\n",
      "nonzero count:, 3567\n",
      "preds_logits: tensor([-0.5580, -0.3248,  0.7525,  1.0948, -2.0867, -1.1107,  0.2378])\n",
      "micro // f1: 1.06, recall: 5.41, precision: 0.59\n",
      "weighted // f1: 4.03, recall: 5.41, precision: 0.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/14 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 7/14 [00:54<00:54,  7.75s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]  \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 0:  57%|█████▋    | 8/14 [00:56<00:42,  7.02s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]\n",
      "Epoch 0:  64%|██████▍   | 9/14 [00:57<00:31,  6.38s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]\n",
      "Epoch 0:  71%|███████▏  | 10/14 [00:58<00:23,  5.87s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]\n",
      "Epoch 0:  79%|███████▊  | 11/14 [01:00<00:16,  5.50s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]\n",
      "Epoch 0:  86%|████████▌ | 12/14 [01:01<00:10,  5.15s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]\n",
      "Epoch 0:  93%|█████████▎| 13/14 [01:03<00:04,  4.87s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]\n",
      "Epoch 0: 100%|██████████| 14/14 [01:03<00:00,  4.56s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tp: 0\n",
      "nonzero count:, 0\n",
      "preds_logits: tensor([  88.6416,   85.6447,   22.0767, -124.7560, -112.0170,   13.8141,\n",
      "        -119.8799])\n",
      "micro // f1: 0.00, recall: 0.00, precision: 0.00\n",
      "weighted // f1: 0.00, recall: 0.00, precision: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 14/14 [01:03<00:00,  4.56s/it, loss=1.28e+03, v_num=62, train_loss_step=310.0]\n",
      "Epoch 1:   0%|          | 0/14 [00:00<?, ?it/s, loss=1.28e+03, v_num=62, train_loss_step=310.0, train_loss_epoch=1.45e+3]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 7/14 [01:28<01:28, 12.62s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]     \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 8/14 [01:30<01:07, 11.28s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]\n",
      "Epoch 1:  64%|██████▍   | 9/14 [01:32<00:51, 10.24s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]\n",
      "Epoch 1:  71%|███████▏  | 10/14 [01:34<00:37,  9.41s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]\n",
      "Epoch 1:  79%|███████▊  | 11/14 [01:35<00:26,  8.70s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]\n",
      "Epoch 1:  86%|████████▌ | 12/14 [01:37<00:16,  8.12s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]\n",
      "Epoch 1:  93%|█████████▎| 13/14 [01:39<00:07,  7.62s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]\n",
      "Epoch 1: 100%|██████████| 14/14 [01:39<00:00,  7.10s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tp: 513\n",
      "nonzero count:, 11265\n",
      "preds_logits: tensor([  7.6541,   5.6231,   9.2959,  -9.4332, -13.3155,   0.7387, -16.3373])\n",
      "micro // f1: 8.20, recall: 41.17, precision: 4.55\n",
      "weighted // f1: 3.59, recall: 41.17, precision: 4.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 14/14 [01:39<00:00,  7.11s/it, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=1.45e+3]\n",
      "Epoch 2:   0%|          | 0/14 [00:00<?, ?it/s, loss=698, v_num=62, train_loss_step=7.870, train_loss_epoch=112.0]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████     | 7/14 [01:46<01:46, 15.22s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 8/14 [01:48<01:21, 13.60s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Epoch 2:  64%|██████▍   | 9/14 [01:50<01:01, 12.27s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Epoch 2:  71%|███████▏  | 10/14 [01:51<00:44, 11.19s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Epoch 2:  79%|███████▊  | 11/14 [01:53<00:31, 10.34s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Epoch 2:  86%|████████▌ | 12/14 [01:55<00:19,  9.62s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Epoch 2:  93%|█████████▎| 13/14 [01:58<00:09,  9.08s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Epoch 2: 100%|██████████| 14/14 [01:58<00:00,  8.47s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tp: 0\n",
      "nonzero count:, 0\n",
      "preds_logits: tensor([ 1.3348,  0.6628,  0.2702, -0.7144, -1.4205,  0.2358, -1.5312])\n",
      "micro // f1: 0.00, recall: 0.00, precision: 0.00\n",
      "weighted // f1: 0.00, recall: 0.00, precision: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 14/14 [01:58<00:00,  8.47s/it, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=112.0]\n",
      "Epoch 3:   0%|          | 0/14 [00:00<?, ?it/s, loss=497, v_num=62, train_loss_step=5.590, train_loss_epoch=29.30]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|█████     | 7/14 [02:12<02:12, 18.91s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 8/14 [02:14<01:41, 16.87s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Epoch 3:  64%|██████▍   | 9/14 [02:16<01:15, 15.17s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Epoch 3:  71%|███████▏  | 10/14 [02:19<00:55, 13.94s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Epoch 3:  79%|███████▊  | 11/14 [02:20<00:38, 12.79s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Epoch 3:  86%|████████▌ | 12/14 [02:22<00:23, 11.85s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Epoch 3:  93%|█████████▎| 13/14 [02:23<00:11, 11.05s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Epoch 3: 100%|██████████| 14/14 [02:24<00:00, 10.30s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tp: 513\n",
      "nonzero count:, 11265\n",
      "preds_logits: tensor([  8.2577,   6.5615,   8.5260,  -9.3597, -27.3703,   5.3974, -26.0650])\n",
      "micro // f1: 8.20, recall: 41.17, precision: 4.55\n",
      "weighted // f1: 3.59, recall: 41.17, precision: 4.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 14/14 [02:24<00:00, 10.30s/it, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=29.30]\n",
      "Epoch 4:   0%|          | 0/14 [00:00<?, ?it/s, loss=44.6, v_num=62, train_loss_step=5.680, train_loss_epoch=18.30]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|█████     | 7/14 [02:25<02:25, 20.73s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 8/14 [02:27<01:50, 18.42s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Epoch 4:  64%|██████▍   | 9/14 [02:29<01:22, 16.57s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Epoch 4:  71%|███████▏  | 10/14 [02:30<01:00, 15.05s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Epoch 4:  79%|███████▊  | 11/14 [02:33<00:41, 13.92s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Epoch 4:  86%|████████▌ | 12/14 [02:34<00:25, 12.88s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Epoch 4:  93%|█████████▎| 13/14 [02:35<00:11, 12.00s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Epoch 4: 100%|██████████| 14/14 [02:36<00:00, 11.18s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tp: 513\n",
      "nonzero count:, 11265\n",
      "preds_logits: tensor([  6.3035,   6.5229,   6.7505,  -9.1935, -30.4175,   5.4487, -30.4645])\n",
      "micro // f1: 8.20, recall: 41.17, precision: 4.55\n",
      "weighted // f1: 3.59, recall: 41.17, precision: 4.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [02:36<00:00, 11.18s/it, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.30]\n",
      "Epoch 5:   0%|          | 0/14 [00:00<?, ?it/s, loss=22.4, v_num=62, train_loss_step=4.960, train_loss_epoch=18.90]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|█████     | 7/14 [02:36<02:36, 22.39s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 8/14 [02:39<01:59, 19.94s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Epoch 5:  64%|██████▍   | 9/14 [02:41<01:29, 17.91s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Epoch 5:  71%|███████▏  | 10/14 [02:43<01:05, 16.32s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Epoch 5:  79%|███████▊  | 11/14 [02:45<00:45, 15.00s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Epoch 5:  86%|████████▌ | 12/14 [02:46<00:27, 13.87s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Epoch 5:  93%|█████████▎| 13/14 [02:48<00:12, 12.96s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Epoch 5: 100%|██████████| 14/14 [02:49<00:00, 12.07s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tp: 0\n",
      "nonzero count:, 0\n",
      "preds_logits: tensor([  3.5999,   2.6459,   2.2143,  -2.6841,  -9.5338,   1.1630, -13.0484])\n",
      "micro // f1: 0.00, recall: 0.00, precision: 0.00\n",
      "weighted // f1: 0.00, recall: 0.00, precision: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 14/14 [02:49<00:00, 12.07s/it, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=18.90]\n",
      "Epoch 6:   0%|          | 0/14 [00:00<?, ?it/s, loss=18.6, v_num=62, train_loss_step=5.340, train_loss_epoch=17.70]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goader/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='cpu', devices=1, max_epochs=20, callbacks=[MetricsLoggingCallback()])\n",
    "trainer.fit(model, datamodule=datamodule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['training', '_parameters', '_buffers', '_non_persistent_buffers_set', '_backward_hooks', '_is_full_backward_hook', '_forward_hooks', '_forward_pre_hooks', '_state_dict_hooks', '_load_state_dict_pre_hooks', '_load_state_dict_post_hooks', '_modules', 'prepare_data_per_node', 'allow_zero_length_dataloader_with_multiple_devices', '_log_hyperparams', '_dtype', '_device', '_trainer', '_use_amp', 'precision', '_example_input_array', '_current_fx_name', '_automatic_optimization', '_truncated_bptt_steps', '_param_requires_grad_state', '_metric_attributes', '_should_prevent_trainer_and_dataloaders_deepcopy', '_running_torchscript', 'num_classes', '_hparams_name', '_hparams', '_hparams_initial'])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.predict(model, datamodule=datamodule)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "main",
   "language": "python",
   "display_name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
